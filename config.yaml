experiment:
	folders: &folders
		root:	/Users/alex/Dropbox/nlp_project
		data:	/Users/alex/Dropbox/nlp_project/data
		working:/Users/alex/Dropbox/nlp_project/working
		output:	/Users/alex/Dropbox/nlp_project/output
	data:
		udp: *folders
			sub_data: /input/raw/universal-dependencies-1.0/en  # in the data folder
			training_file: en-ud-train.conllu
			cross_validation_file: en-ud-dev.conllu
			testing_file: en-ud-test.conllu
		udp-tiny: *folders
			sub_data: /input/raw/universal-dependencies-1.0/en  # in the data folder
			training_file: udp-tiny-train.conllu
			cross_validation_file: en-ud-dev.conllu
			testing_file: udp-tiny-test.conllu
	tasks:
		PosTagger:
			memm-baseline:
				# These become parameters to the models
				model: MaxEntMarkovModel
				maxiter: 0
				iterations: 0
				regularization: 0
				method: baseline  # the method to call on the model after 'train' and before 'test'
			memm-simple: &memm-simple
				model: MaxEntMarkovModel
				maxiter: 5
				iterations: 1
				regularization: [0.5]
				method: [train, label]
			memm: &memm
				model: MaxEntMarkovModel
				maxiter: 5
				iterations: 2
				regularization: [0.1, 0.2, 0.3, 0.5, 0.8, 1.3]  # Fibonacci numbers!
				method: [train, label, test]
			ptron:
				model: PerceptronTagger
				method: [train, tag]
		Parser:
			avgtron-memm:
				model: PerceptronParser
				tagger: PosTagger:memm

